{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Blind rotation\n",
    "A blind rotation procdeure is the core of FHEW bootstrapping and other many application of HE supporting non-arithmetic (not $\\times$ or +) operations.\n",
    "\n",
    "It is defined as follows.\n",
    "\n",
    "**Definition (blind rotation)**\n",
    "- Input: LWE ciphertext $(\\beta, \\vec{\\alpha})$, blind rotation keys $brk$ under secret $\\boldsymbol{z}$, and public polynomial $f$, where $\\beta + \\left< \\vec{\\alpha}, \\vec{s}\\right> = u$\n",
    "- Output: $RLWE_{\\boldsymbol{z}}(f\\cdot X^u)$\n",
    "\n",
    "It is compose of following three steps.\n",
    "1. Make a encryption of $f\\cdot X^{\\beta}$, $ACC$. It can easily be done $ACC = (f\\cdot X^{\\beta}, 0)$.\n",
    "2. Accumulation: homomophically multiply $X^{\\alpha_i s_i}$ to $ACC$ and update it.\n",
    "3. After accumulation, we get $RLWE_{\\boldsymbol{z}}(f\\cdot X^{\\beta + \\left< \\vec{\\alpha}, \\vec{s}\\right>}) = RLWE_{\\boldsymbol{z}}(f\\cdot X^u)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from previous lecturenote\n",
    "import torch\n",
    "import math\n",
    "\n",
    "stddev = 3.2\n",
    "logQ = 27\n",
    "\n",
    "N = 2**10\n",
    "Q = 2**logQ\n",
    "\n",
    "def keygen(dim):\n",
    "    return torch.randint(2, size = (dim,))\n",
    "\n",
    "def errgen(stddev):\n",
    "    e = torch.round(stddev*torch.randn(1))\n",
    "    e = e.squeeze()\n",
    "    return e.to(torch.int)\n",
    "\n",
    "def errgen(stddev, N):\n",
    "    e = torch.round(stddev*torch.randn(N))\n",
    "    e = e.squeeze()\n",
    "    return e.to(torch.int)\n",
    "\n",
    "def uniform(dim, modulus):\n",
    "    return torch.randint(modulus, size = (dim,), dtype=torch.int32)\n",
    "\n",
    "def polymult(a, b, dim, modulus):\n",
    "    res = torch.zeros(dim).to(torch.int)\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            if i >= j:\n",
    "                res[i] += a[j]*b[i-j]\n",
    "                res[i] %= modulus\n",
    "            else:\n",
    "                res[i] -= a[j]*b[i-j] # Q - x mod Q = -x\n",
    "                res[i] %= modulus\n",
    "\n",
    "    res %= modulus\n",
    "    return res\n",
    "\n",
    "root_powers = torch.arange(N//2).to(torch.complex128)\n",
    "root_powers = torch.exp((1j*math.pi/N)*root_powers)\n",
    "\n",
    "root_powers_inv = torch.arange(0,-N//2,-1).to(torch.complex128)\n",
    "root_powers_inv = torch.exp((1j*math.pi/N)*root_powers_inv)\n",
    "\n",
    "def negacyclic_fft(a, N, Q):\n",
    "    acomplex = a.to(torch.complex128)\n",
    "\n",
    "    a_precomp = (acomplex[...,:N//2] + 1j * acomplex[..., N//2:]) * root_powers\n",
    "\n",
    "    return torch.fft.fft(a_precomp)\n",
    "\n",
    "def negacyclic_ifft(A, N, Q):\n",
    "    b = torch.fft.ifft(A)\n",
    "    b *= root_powers_inv\n",
    "\n",
    "    a = torch.cat((b.real, b.imag), dim=-1)\n",
    "    # Rounding should be more accurate\n",
    "    # a += 0.5\n",
    "\n",
    "    aint = a.to(torch.int32)\n",
    "    # only when Q is a power-of-two\n",
    "    aint &= Q-1\n",
    "\n",
    "    return aint\n",
    "\n",
    "# make an RLWE encryption of message\n",
    "def encrypt_to_fft(m, sfft):\n",
    "    ct = torch.stack([errgen(stddev, N), uniform(N, Q)])\n",
    "    ctfft = negacyclic_fft(ct, N, Q)\n",
    "\n",
    "    ctfft[0] += -ctfft[1]*sfft + negacyclic_fft(m, N, Q)\n",
    "\n",
    "    return ctfft\n",
    "\n",
    "def normalize(v, logQ):\n",
    "    # same as follows but no branch\n",
    "    \"\"\"\n",
    "    if v > Q//2:\n",
    "        v -= Q\n",
    "    \"\"\"\n",
    "    # vmod Q when Q is a power-of-two\n",
    "    Q = (1 << logQ)\n",
    "    v &= Q-1\n",
    "    # get msb\n",
    "    msb = (v & Q//2) >> (logQ - 1)\n",
    "    v -= (Q) * msb\n",
    "    return v\n",
    "\n",
    "def decrypt_from_fft(ctfft, sfft):\n",
    "    assert len(ctfft.size()) == 2\n",
    "    # normalization is optional\n",
    "    # return normalize(negacyclic_ifft(ctfft[0] + ctfft[1]*sfft, N, Q), logQ)\n",
    "    return negacyclic_ifft(ctfft[0] + ctfft[1]*sfft, N, Q)\n",
    "\n",
    "# we will use B-ary decomposition, i.e., cut digits by logB bits\n",
    "d = 3\n",
    "logB = 7\n",
    "\n",
    "decomp_shift = logQ - logB*torch.arange(d,0,-1).view(d,1)\n",
    "mask = (1 << logB) - 1\n",
    "\n",
    "gvector = 1 << decomp_shift\n",
    "\n",
    "def decompose(a):\n",
    "    \n",
    "    assert len(a.size()) <= 2\n",
    "    # for RLWE'\n",
    "    if len(a.size()) == 1:\n",
    "        res = (a.unsqueeze(0) >> decomp_shift.view(d, 1)) & mask\n",
    "        return res\n",
    "    # for RGSW\n",
    "    elif len(a.size()) == 2:\n",
    "        res = (a.unsqueeze(0) >> decomp_shift.view(d, 1, 1)) & mask\n",
    "        return res\n",
    "\n",
    "msbmask = 0\n",
    "for i in decomp_shift:\n",
    "    msbmask += (1<<(i+logB-1))\n",
    "\n",
    "bin(msbmask)[2:]\n",
    "\n",
    "# about twice heavier than unsigned decomposition\n",
    "# it returns value -B/2 <= * <= B/2, not < B/2, but okay\n",
    "def signed_decompose(a):\n",
    "    # carry\n",
    "    da = decompose(a + (a & msbmask))\n",
    "    # -B\n",
    "    da -= decompose((a & msbmask))\n",
    "    return da\n",
    "\n",
    "def encrypt_rgsw_fft(z, skfft):\n",
    "    # RGSW has a dimension of d, 2, 2, N\n",
    "    rgsw = torch.zeros(d, 2, 2, N, dtype=torch.int32)\n",
    "\n",
    "    # generate the 'a' part\n",
    "    # INSECURE: to be fixed later\n",
    "    rgsw[:, :, 1, :] = torch.randint(Q, size = (d, 2 , N), dtype= torch.int32)\n",
    "\n",
    "    # add error on b\n",
    "    # INSECURE: to be fixed later\n",
    "    rgsw[:, :, 0, :] = torch.round(stddev * torch.randn(size = (d, 2, N)))\n",
    "\n",
    "    # following is equal to rgsw %= Q, but a faster version\n",
    "    rgsw &= (Q-1)\n",
    "    rgsw = normalize(rgsw, logQ)\n",
    "\n",
    "    # do fft for easy a*s\n",
    "    rgswfft = negacyclic_fft(rgsw, N, Q)\n",
    "\n",
    "    # now b = -a*sk + e\n",
    "    rgswfft[:, :, 0, :] -= rgswfft[:, :, 1, :] * skfft.view(1, 1, N//2)\n",
    "\n",
    "    # encrypt (z, z*sk) multiplied by g\n",
    "    gzfft = negacyclic_fft(gvector * z, N, Q)\n",
    "    rgswfft[:, 0, 0, :] += gzfft\n",
    "    rgswfft[:, 1, 1, :] += gzfft\n",
    "\n",
    "    return rgswfft\n",
    "\n",
    "def rgswmult(ctfft, rgswfft):\n",
    "    ct = negacyclic_ifft(ctfft, N, Q)\n",
    "    dct = signed_decompose(ct)\n",
    "    multfft = negacyclic_fft(dct, N, Q).view(d, 2, 1, N//2) * rgswfft\n",
    "    \n",
    "    return torch.sum(multfft, dim = (0,1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 CMux gate\n",
    "\n",
    "In each iteration, we need to multiply $RGSW(X^{\\alpha_i s_i})$, where $\\alpha_i$ is public and $s_i$ is given in encrypted from.\n",
    "The variants: AP/DM, GINX/CGGI, and LMKCDEY differ in generation of encrypted $X^{\\alpha_i s_i}$.\n",
    "\n",
    "In GINX variant blind rotation for *binary secrets*, we use the following CMux gate as subprocess.\n",
    "$$\n",
    "X^{\\alpha_i s_i} = (1-s_i) + X^{\\alpha_i} \\cdot s_i\n",
    "$$\n",
    "There are only two possible cases = $s_i$ is $0$ or $1$ - thus, we can easily see that the equation holds in both cases.\n",
    "\n",
    "1. $s_i = 0$\n",
    "$$\n",
    "X^{\\alpha_i s_i} = (1-s_i) + X^{\\alpha_i} \\cdot s_i \\\\\n",
    "    = (1-0) + 0\\\\\n",
    "    = X^0 \n",
    "$$\n",
    "2. $s_i = 1$\n",
    "$$\n",
    "X^{\\alpha_i s_i} = (1-1) + X^{\\alpha_i} \\cdot 1 \\\\\n",
    "    = (1-1) +  X^{\\alpha_i}\\\\\n",
    "    = X^{\\alpha_i}\n",
    "$$\n",
    "\n",
    "Hence, we calculate the following in each iteration\n",
    "$$\n",
    "ACC \\leftarrow ACC \\circledast ((1-RGSW(s_i)) + X^{\\alpha_i} \\cdot RGSW(s_i)),\n",
    "$$\n",
    "which can be computed efficiently with\n",
    "$$\n",
    "ACC \\leftarrow ACC  + (X^{\\alpha_i} - 1 ) \\cdot ACC\\circledast RGSW(s_i).\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the GINX accumulation in the following codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1\n",
    "skN = keygen(N)\n",
    "skNfft = negacyclic_fft(skN, N, Q)\n",
    "\n",
    "sPoly = torch.zeros([N], dtype=torch.int32)\n",
    "sPoly[0] = s\n",
    "\n",
    "rgswKey = encrypt_rgsw_fft(sPoly, skNfft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      0, 1000000, 2000000,  ..., 1000000, 2000000, 3000000],\n",
       "        [      0,       0,       0,  ...,       0,       0,       0]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACC is transparent encryption of (0,1,2, ..., N)\n",
    "ACC = torch.zeros([2,N], dtype=torch.int32)\n",
    "for i in range(N):\n",
    "    ACC[0][i] = (i%10) * 1000000\n",
    "\n",
    "ACCfft = negacyclic_fft(ACC, N, Q)\n",
    "\n",
    "ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "alphaPoly = torch.zeros([N], dtype=torch.int32)\n",
    "alphaPoly[0] = -1\n",
    "alphaPoly[alpha] = 1\n",
    "\n",
    "alphaPolyfft = negacyclic_fft(alphaPoly, N, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulation\n",
    "temp = rgswmult(ACCfft, rgswKey)\n",
    "ACCfft += alphaPolyfft * temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([107240719,  13388392,  67389239,  94891949, 108328708,  79879031,\n",
       "        105447611, 120037201,  71632247,  49894554], dtype=torch.int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrypt_from_fft(temp, skNfft)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 55621463,  93852326,  80216880, 106715019, 120780968,  28449677,\n",
       "        108649149, 119628138,  48404954,  21737693], dtype=torch.int32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrypt_from_fft(alphaPolyfft * temp, skNfft)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([131211942,    998322,   3002208,   5002741,   7006116,   9012927,\n",
       "         11014387,  13009728,  15000824,  17002389], dtype=torch.int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrypt_from_fft(ACCfft, skNfft)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = decrypt_from_fft(ACCfft, skNfft)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3005786,   998322,  3002208,  5002741,  7006116,  9012927, 11014387,\n",
       "        13009728, 15000824, 17002389], dtype=torch.int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(dm, logQ)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we generate $f$ for NAND gate.\n",
    "$[-q/8, 3q/8]$ is mapped to $q/8$, and $[3q/8, 7q/8]$ is mapped to $-q/8$\n",
    "\n",
    "NOTE: $f$ depends on the binary gate we want to perform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 2*N\n",
    "f_nand = torch.zeros(size=[N], dtype=torch.int32)\n",
    "\n",
    "f_nand -= (Q>>3)\n",
    "f_nand[3*q//8:] += (Q>>2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
