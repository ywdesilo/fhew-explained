{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gadget decomposition\n",
    "\n",
    "**GOAL:** for a given polynomial $\\boldsymbol{a}$ and an encryption $\\textsf{RLWE}(m)$ (or something similar to it), find $\\textsf{RLWE}(\\boldsymbol{a}\\cdot \\boldsymbol{m})$, with small noise.\n",
    "\n",
    "Gadget decomposition and $RLWE'$ technique allows us to multiply ciphertext to a *large* constant with *small* noise increment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RLWE' is usually used for the key switching. We make an example of key switching from s1 to s2 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from previous lecturenote\n",
    "import torch\n",
    "import math\n",
    "\n",
    "stddev = 3.2\n",
    "logQ = 27\n",
    "\n",
    "N = 2**10\n",
    "Q = 2**logQ\n",
    "\n",
    "\n",
    "def keygen(dim):\n",
    "    return torch.randint(2, size = (dim,))\n",
    "\n",
    "def errgen(stddev):\n",
    "    e = torch.round(stddev*torch.randn(1))\n",
    "    e = e.squeeze()\n",
    "    return e.to(torch.int)\n",
    "\n",
    "def errgen(stddev, N):\n",
    "    e = torch.round(stddev*torch.randn(N))\n",
    "    e = e.squeeze()\n",
    "    return e.to(torch.int)\n",
    "\n",
    "def uniform(dim, modulus):\n",
    "    return torch.randint(modulus, size = (dim,))\n",
    "\n",
    "def polymult(a, b, dim, modulus):\n",
    "    res = torch.zeros(dim).to(torch.int)\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            if i >= j:\n",
    "                res[i] += a[j]*b[i-j]\n",
    "                res[i] %= modulus\n",
    "            else:\n",
    "                res[i] -= a[j]*b[i-j] # Q - x mod Q = -x\n",
    "                res[i] %= modulus\n",
    "\n",
    "    res %= modulus\n",
    "    return res\n",
    "\n",
    "root_powers = torch.arange(N//2).to(torch.complex128)\n",
    "root_powers = torch.exp((1j*math.pi/N)*root_powers)\n",
    "\n",
    "root_powers_inv = torch.arange(0,-N//2,-1).to(torch.complex128)\n",
    "root_powers_inv = torch.exp((1j*math.pi/N)*root_powers_inv)\n",
    "\n",
    "def negacyclic_fft(a, N, Q):\n",
    "    acomplex = a.to(torch.complex128)\n",
    "\n",
    "    a_precomp = (acomplex[...,:N//2] + 1j * acomplex[..., N//2:]) * root_powers\n",
    "\n",
    "    return torch.fft.fft(a_precomp)\n",
    "\n",
    "def negacyclic_ifft(A, N, Q):\n",
    "    b = torch.fft.ifft(A)\n",
    "    b *= root_powers_inv\n",
    "\n",
    "    a = torch.cat((b.real, b.imag), dim=-1)\n",
    "\n",
    "    aint = a.to(torch.int32)\n",
    "    # only when Q is a power-of-two\n",
    "    aint &= Q-1\n",
    "\n",
    "    return aint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate two keys\n",
    "s1 = keygen(N)\n",
    "s2 = keygen(N)\n",
    "\n",
    "s1fft = negacyclic_fft(s1, N, Q)\n",
    "s2fft = negacyclic_fft(s2, N, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an RLWE encryption of message\n",
    "def encrypt_to_fft(m, sfft):\n",
    "    ct = torch.stack([errgen(stddev, N), uniform(N, Q)])\n",
    "    ctfft = negacyclic_fft(ct, N, Q)\n",
    "\n",
    "    ctfft[0] += -ctfft[1]*sfft + negacyclic_fft(m, N, Q)\n",
    "\n",
    "    return ctfft\n",
    "\n",
    "def normalize(v, Q):\n",
    "    # same as follows but no branch\n",
    "    \"\"\"\n",
    "    if v > Q//2:\n",
    "        v -= Q\n",
    "    \"\"\"\n",
    "    # vmod Q when Q is a power-of-two\n",
    "    v &= Q-1\n",
    "    # get msb\n",
    "    msb = (v & Q//2) >>  (logQ - 1)\n",
    "    v -= (Q) * msb\n",
    "    return v\n",
    "\n",
    "def decrypt_from_fft(ctfft, sfft):\n",
    "    return normalize(negacyclic_ifft(ctfft[0] + ctfft[1]*sfft, N, Q), Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000000,       0,       0,  ...,       0,       0,       0],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.zeros((N), dtype=torch.int32)\n",
    "m[0] = 1000000\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000005,       0,      -1,  ...,       4,       5,       3],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctfft = encrypt_to_fft(m, s1fft)\n",
    "mdec = decrypt_from_fft(ctfft, s1fft)\n",
    "mdec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot decrypt mdec with s2, as the secret key is different. It should look like a random value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 63399288, -64490656,  48043841,  ..., -46120466, -36731917,\n",
       "        -52329847], dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdec_wrong = decrypt_from_fft(ctfft, s2fft)\n",
    "mdec_wrong"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to transform ct as a ciphertext of the same message but with different key s2 *without decryption*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Gadget decomposition\n",
    "\n",
    "We define *gadget decomposition* $h$ corresponding to gadget vector $\\vec{g} = (g_0, g_1, \\dots, g_{d-1})$ as follows.\n",
    "$$\n",
    "h: \\mathbb{Z} \\longmapsto \\mathbb{Z}^d\n",
    "$$\n",
    "$$\n",
    "||h(a)|| < B, \\left< h(a), \\vec{g}\\right> = a,\n",
    "$$\n",
    "where B is a upper bound.\n",
    "\n",
    "Also, we can naturally extend it to $\\mathcal{R}$ and $\\mathbb{Z}^n$.\n",
    "\n",
    "For example, a number $77 = 0\\text{b}01001101$ can be decomposed to $(0,1,0,0,1,1,0,1)$ when $\\vec{g} = (2^7, 2^6, \\dots, 1)$ and $B=2$\n",
    "\n",
    "Otherwise, it can also be decomposed to $(1,0,3,1)$ when $\\vec{g} = (4^3, 4^2, 4, 1)$, and $B=4$ here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can do a *approximate gadget decomposition* where $\\left< h(a), \\vec{g}\\right> \\approx a$, i.e., $\\left< h(a), \\vec{g}\\right>$ is not exactly the same but similar to $a$.\n",
    "\n",
    "We first set d and B satisfying $B^{d} \\le Q \\le B^{d+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use B-ary decomposition, i.e., cut digits by logB bits\n",
    "d = 4\n",
    "logB = 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shift by amount of decomp_shit and cut `logB` MSBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21],\n",
       "        [15],\n",
       "        [ 9],\n",
       "        [ 3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomp_shift = logQ - logB*torch.arange(1,d+1).view(d,1)\n",
    "decomp_shift\n",
    "\n",
    "mask = (1 << logB) - 1\n",
    "\n",
    "decomp_shift"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the gadget vector, \n",
    "$$\n",
    "\\vec{g} = (B^{d-1}, \\dots, B^2, B)\n",
    "$$\n",
    "is given as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2097152],\n",
       "        [  32768],\n",
       "        [    512],\n",
       "        [      8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gvector = 1 << decomp_shift\n",
    "gvector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decomposition function handles both RLWE' and RGSW case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(a):\n",
    "    \n",
    "    assert len(a.size()) <= 2\n",
    "    # for RLWE'\n",
    "    if len(a.size()) == 1:\n",
    "        return (a.unsqueeze(0) >> decomp_shift.view(d, 1)) & mask\n",
    "    # for RGSW\n",
    "    elif len(a.size()) == 2:\n",
    "        return (a.unsqueeze(0) >> decomp_shift.view(d, 1, 1)) & mask\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a test case for RGSW multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 89967997,  32298693, 127347069,  ...,  85314453, 124195547,\n",
       "         77610676])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = uniform(N, Q)\n",
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the decomposed vector always has value less than $B = 2^7 = 128$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42, 15, 60,  ..., 40, 59, 37],\n",
       "        [57, 25, 46,  ..., 43, 14,  0],\n",
       "        [38, 43, 20,  ..., 37,  9, 31],\n",
       "        [47, 24, 47,  ..., 50, 27, 22]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = decompose(a)\n",
    "# see all values are smaller than 2^6 = 64\n",
    "da"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See $<h(a), \\vec{g}> \\approx a$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 89967992,  32298688, 127347064,  ...,  85314448, 124195544,\n",
       "         77610672])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#composition is inner product, see it is similar to a\n",
    "torch.sum(da * gvector, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 89967997,  32298693, 127347069,  ...,  85314453, 124195547,\n",
       "         77610676])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend it to a ciphertext too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:\n",
      " tensor([33554432.,        0.,        0., 33554432.,        0.,        0.,\n",
      "               0.,        0.,        0.,        0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 78261488,  48908637, 104842057,  ..., 124799417,  50596974,\n",
       "         115122275],\n",
       "        [ 29809111,  22452249,  54435983,  ..., 131073647, 100503685,\n",
       "          81545739]], dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.zeros(N)\n",
    "m[0] = Q//4\n",
    "m[3] = Q//4\n",
    "print(\"m:\\n\", m[:10])\n",
    "ctfft = encrypt_to_fft(m, s1fft)\n",
    "ct = negacyclic_ifft(ctfft, N, Q)\n",
    "ct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see the message part in the next subsection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 78261488,  48908632, 104842056,  ..., 124799416,  50596968,\n",
       "         115122272],\n",
       "        [ 29809104,  22452248,  54435976,  ..., 131073640, 100503680,\n",
       "          81545736]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctnew = torch.sum(decompose(ct) * gvector.view(d, 1, 1), dim = 0)\n",
    "ctnew"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decrypt it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:\n",
      " tensor([33554432.,        0.,        0., 33554432.,        0.,        0.,\n",
      "               0.,        0.,        0.,        0.])\n",
      "dm:\n",
      " tensor([33556440,     2025,     1936, 33556352,     1888,     1992,     1952,\n",
      "            1968,     1920,     1872], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "ctnewfft = negacyclic_fft(ctnew, N, Q)\n",
    "\n",
    "dm = decrypt_from_fft(ctnewfft, s1fft)[:10]\n",
    "print(\"m:\\n\", m[:10])\n",
    "print(\"dm:\\n\", dm[:10])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.RLWE' Ciphertext and key switching keys.\n",
    "\n",
    "We can make a tuple of RLWE ciphertexts corresponding to a gadget vector $\\vec{g} = (g_0, \\dots, g_{d-1})$, and call it RLWE'.\n",
    "$$\n",
    "RLWE'( \\boldsymbol{s} ) =\\left( RLWE(g_0 \\boldsymbol{s}), RLWE(g_1 \\boldsymbol{s}), \\dots, RLWE(g_{d-1} \\boldsymbol{s})  \\right) \n",
    "\\in \\mathcal{R}^{d\\times N}\n",
    "$$\n",
    "\n",
    "Then the inner product between $h(\\boldsymbol{m})$ and $RLWE'( \\boldsymbol{s} )$ will give us RLWE (not RLWE'!!!) encryption of $\\boldsymbol{m\\cdot s}$, $RLWE(\\boldsymbol{m \\cdot s})$.\n",
    "The correctness can be seen as follows:\n",
    "$$\n",
    "\\left<(\\boldsymbol{m}_0, \\dots, \\boldsymbol{m}_{d-1}),  \\left( RLWE(g_0 \\boldsymbol{s}), \\dots, RLWE(g_{d-1} \\boldsymbol{s})  \\right) \\right>\n",
    "= \\sum_{i = 0}^{d-1} (\\boldsymbol{m}_i \\cdot RLWE(g_i \\boldsymbol{s}))\n",
    "= RLWE( \\sum_{i = 0}^{d-1} (\\boldsymbol{m}_i \\cdot g_i \\boldsymbol{s}))\n",
    "= RLWE( \\sum_{i = 0}^{d-1} (\\boldsymbol{m} \\cdot \\boldsymbol{s}))\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2.1. Error analysis (why RLWE'?)\n",
    "\n",
    "We can also get a ciphertext of $RLWE(\\boldsymbol{m}\\boldsymbol{s})$ by multiplying $\\boldsymbol{m}$ to each element  of $RLWE(\\boldsymbol{s})$.\n",
    "In other words, $(\\boldsymbol{m} \\cdot \\boldsymbol{b}, \\boldsymbol{m}\\cdot \\boldsymbol{a})$ is $RLWE(\\boldsymbol{m}\\boldsymbol{s})$, \n",
    "where $RLWE(\\boldsymbol{s}) = (\\boldsymbol{b}, \\boldsymbol{a})$.\n",
    "\n",
    "**Naive multiplication**\n",
    "\n",
    "However, an error $\\boldsymbol{e}$ is contained in $RLWE(\\boldsymbol{s})$, so the decryption $\\boldsymbol{b} + \\boldsymbol{a} \\cdot  \\boldsymbol{s}$ will be given as \n",
    "$$ \n",
    "\\boldsymbol{s} +  \\boldsymbol{e}.\n",
    "$$\n",
    "Thus, the decryption of $RLWE(\\boldsymbol{ms}) = (\\boldsymbol{mb}, \\boldsymbol{ma})$ results in $ \\boldsymbol{ms} +  \\boldsymbol{me}$.\n",
    "\n",
    "**Multiplication using RLWE'**\n",
    "\n",
    "It is okay when $\\boldsymbol{m}$ is small (so it is used to multiply a small constant), but we usually need to to multiply $\\boldsymbol{m}$ uniformly sampled in $\\mathbb{Z}_Q$.\n",
    "In this case, the error variance will be $O(Q^2 \\sigma^2)$, where $\\sigma$ is variance of $\\boldsymbol{e}$, and it overwhelms the message.\n",
    "\n",
    "Instead, if we use the RLWE' product, each ciphertext $RLWE'(g_i \\boldsymbol{s})$ is multiplied by $\\boldsymbol{m}_i$, whose size is smaller than $B$.\n",
    "Assuming they are uniformly distributed, the error variance of $RLWE'(\\boldsymbol{m}_i g_i \\boldsymbol{s})$ should be $B^2/12 \\sigma^2$.\n",
    "Adding $d$ of them, the error variance is  \n",
    "$$\n",
    "dB^2/12 \\sigma^2,\n",
    "$$ \n",
    "where $B = Q^{1/d} \\ll Q$.\n",
    "\n",
    "Naive multiplication is *infeasible* when $\\boldsymbol{m}$ is large, which is exactly the case we want. \n",
    "So, we need RLWE' ciphertext (as key) and multiplication using it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encrypt a key using RLWE' ciphertext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [  1788411,  62139972,  70842809,  ...,   7371080,  14571503,\n",
       "           41590556]],\n",
       "\n",
       "        [[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [ 32409271, 120764302,   5680244,  ...,  24170642,  95132708,\n",
       "           56714077]],\n",
       "\n",
       "        [[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [ 34838124,  76878026,   2307585,  ..., 100510751,  71217482,\n",
       "          110731723]],\n",
       "\n",
       "        [[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [ 34404428,  12475759, 118260867,  ..., 126818329,  10023518,\n",
       "          114571333]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it has a dimension of d, 2, N\n",
    "rlwep = torch.zeros(d, 2, N, dtype=torch.int32)\n",
    "\n",
    "# generate the 'a' part\n",
    "rlwep[:, 1, :] = torch.randint(Q, size = (d, N), dtype= torch.int32)\n",
    "\n",
    "rlwep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[       -6,         1,        -9,  ...,        -2,        -3,\n",
       "                  3],\n",
       "         [  1788411,  62139972,  70842809,  ...,   7371080,  14571503,\n",
       "           41590556]],\n",
       "\n",
       "        [[        0,        -2,         3,  ...,        -4,        -1,\n",
       "                 -3],\n",
       "         [ 32409271, 120764302,   5680244,  ...,  24170642,  95132708,\n",
       "           56714077]],\n",
       "\n",
       "        [[       -6,         2,         2,  ...,        -2,         2,\n",
       "                  1],\n",
       "         [ 34838124,  76878026,   2307585,  ..., 100510751,  71217482,\n",
       "          110731723]],\n",
       "\n",
       "        [[       -1,        -6,        -5,  ...,        -4,        -1,\n",
       "                 -2],\n",
       "         [ 34404428,  12475759, 118260867,  ..., 126818329,  10023518,\n",
       "          114571333]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add error on b\n",
    "rlwep[:, 0, :] = torch.round(stddev * torch.randn(size = (d, N)))\n",
    "\n",
    "rlwep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[134217722,         1, 134217719,  ..., 134217726, 134217725,\n",
       "                  3],\n",
       "         [  1788411,  62139972,  70842809,  ...,   7371080,  14571503,\n",
       "           41590556]],\n",
       "\n",
       "        [[        0, 134217726,         3,  ..., 134217724, 134217727,\n",
       "          134217725],\n",
       "         [ 32409271, 120764302,   5680244,  ...,  24170642,  95132708,\n",
       "           56714077]],\n",
       "\n",
       "        [[134217722,         2,         2,  ..., 134217726,         2,\n",
       "                  1],\n",
       "         [ 34838124,  76878026,   2307585,  ..., 100510751,  71217482,\n",
       "          110731723]],\n",
       "\n",
       "        [[134217727, 134217722, 134217723,  ..., 134217724, 134217727,\n",
       "          134217726],\n",
       "         [ 34404428,  12475759, 118260867,  ..., 126818329,  10023518,\n",
       "          114571333]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# following is equal to rlwep %= Q, but a faster version\n",
    "rlwep &= (Q-1)\n",
    "\n",
    "rlwep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do fft for easy a*s\n",
    "rlwepfft = negacyclic_fft(rlwep, N, Q)\n",
    "\n",
    "# now b = -a*s2 + e\n",
    "rlwepfft[:, 0, :] -= rlwepfft[:, 1, :] * s2fft.view(1,N//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 50119422,  47955367,  26405086,  ...,  34553414,   2621741,\n",
       "          119429386],\n",
       "         [  1788410,  62139972,  70842808,  ...,   7371080,  14571503,\n",
       "           41590556]],\n",
       "\n",
       "        [[ 54748284,  51041966, 122316881,  ..., 128565749, 112924448,\n",
       "           93543278],\n",
       "         [ 32409271, 120764301,   5680243,  ...,  24170641,  95132708,\n",
       "           56714076]],\n",
       "\n",
       "        [[ 51752204, 111493915, 130581677,  ...,  94512669,   9606886,\n",
       "           44266644],\n",
       "         [ 34838124,  76878025,   2307585,  ..., 100510751,  71217481,\n",
       "          110731723]],\n",
       "\n",
       "        [[ 65578592,  23817502, 106096809,  ..., 118350180,  19965836,\n",
       "           64858278],\n",
       "         [ 34404428,  12475758, 118260866,  ..., 126818329,  10023518,\n",
       "          114571333]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return back to R_Q\n",
    "rlwepifft = negacyclic_ifft(rlwepfft, N, Q)\n",
    "\n",
    "rlwepifft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      0,       0, 2097152,  ..., 2097152,       0, 2097152],\n",
       "        [      0,       0,   32768,  ...,   32768,       0,   32768],\n",
       "        [      0,       0,     512,  ...,     512,       0,     512],\n",
       "        [      0,       0,       8,  ...,       8,       0,       8]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add decomposition of s1* vec{g}\n",
    "gs1 = gvector * s1\n",
    "\n",
    "gs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlwepifft[:, 0, :] += gs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksk = negacyclic_fft(rlwepifft, N, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksk.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 78261488,  48908637, 104842057,  ..., 124799417,  50596974,\n",
       "         115122275],\n",
       "        [ 29809111,  22452249,  54435983,  ..., 131073647, 100503685,\n",
       "          81545739]], dtype=torch.int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([33554434,        1,       -3, 33554428,       -3,       -1,        3,\n",
      "              -3,       -6,        2], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "mdec = decrypt_from_fft(ctfft, s1fft)\n",
    "print(mdec[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = decompose(ct[1])\n",
    "dctfft = negacyclic_fft(dct, N, Q)\n",
    "dctfft.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 29809111,  22452249,  54435983,  ..., 131073647, 100503685,\n",
      "         81545739], dtype=torch.int32)\n",
      "tensor([ 29809104,  22452248,  54435976,  ..., 131073640, 100503680,\n",
      "         81545736])\n"
     ]
    }
   ],
   "source": [
    "print(ct[1])\n",
    "print(torch.sum(dct*gvector, dim = 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is\n",
    "$$\n",
    "a \\odot RLWE'_{s2}(s1) = RLWE_{s2}(a \\cdot s1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 512]),\n",
       " tensor([[-3.5543e+15-2.1110e+13j, -4.2696e+14+4.5262e+11j,\n",
       "          -7.4475e+13-5.3100e+12j,  ...,\n",
       "          -2.5621e+13-2.7907e+11j, -4.9874e+13-6.9953e+12j,\n",
       "          -1.5260e+14-1.2814e+13j],\n",
       "         [-3.5234e+15-1.0319e+14j, -3.9655e+14-1.3726e+13j,\n",
       "          -9.4416e+13-8.3850e+11j,  ...,\n",
       "          -2.7011e+13+2.3127e+12j, -3.6247e+13-1.1700e+12j,\n",
       "          -1.5074e+14+2.9692e+12j]], dtype=torch.complex128))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodfft = dctfft.view(d, 1, N//2) * ksk\n",
    "prodsumfft = torch.sum(prodfft, dim = 0)\n",
    "\n",
    "prodsumfft.size(), prodsumfft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding $b$ to above, we get\n",
    "$$\n",
    "RLWE_{\\boldsymbol{s2}}(\\boldsymbol{a} \\cdot \\boldsymbol{s1}) + (\\boldsymbol{b}, \\boldsymbol{0}) = RLWE_{\\boldsymbol{s2}}(\\boldsymbol{a} \\cdot \\boldsymbol{s1} + \\boldsymbol{b})\n",
    "= RLWE_{\\boldsymbol{s2}}(\\boldsymbol{m} )\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodsumfft[0] += ctfft[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can decrypt using the switched key $s_2$.\n",
    "\n",
    "Check if the decryption is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:\n",
      " tensor([33554432.,        0.,        0., 33554432.,        0.,        0.,\n",
      "               0.,        0.,        0.,        0.])\n",
      "decrypted:\n",
      " tensor([33841568,   291707,   361954, 33963323,   431422,   478976,   518779,\n",
      "          556394,   623830,   634522], dtype=torch.int32)\n",
      "decrypted (scaled to 1):\n",
      " tensor([1.0086, 0.0087, 0.0108, 1.0122, 0.0129, 0.0143, 0.0155, 0.0166, 0.0186,\n",
      "        0.0189])\n"
     ]
    }
   ],
   "source": [
    "mks = decrypt_from_fft(prodsumfft, s2fft)\n",
    "print(\"m:\\n\",m[:10])\n",
    "print(\"decrypted:\\n\",mks[:10])\n",
    "print(\"decrypted (scaled to 1):\\n\",mks[:10]/(Q//4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
