{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gadget decomposition\n",
    "\n",
    "**GOAL:** for a given polynomial $\\boldsymbol{a}$ and an encryption $\\textsf{RLWE}(m)$ (or something similar to it), find $\\textsf{RLWE}(\\boldsymbol{a}\\cdot \\boldsymbol{m})$, with small noise.\n",
    "\n",
    "Gadget decomposition and $RLWE'$ technique allows us to multiply ciphertext to a *large* constant with *small* noise increment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RLWE' is usually used for the key switching. We make an example of key switching from s1 to s2 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from previous lecturenote\n",
    "import torch\n",
    "import math\n",
    "\n",
    "stddev = 3.2\n",
    "logQ = 27\n",
    "\n",
    "N = 2**10\n",
    "Q = 2**logQ\n",
    "\n",
    "\n",
    "def keygen(dim):\n",
    "    return torch.randint(2, size = (dim,))\n",
    "\n",
    "def errgen(stddev):\n",
    "    e = torch.round(stddev*torch.randn(1))\n",
    "    e = e.squeeze()\n",
    "    return e.to(torch.int)\n",
    "\n",
    "def errgen(stddev, N):\n",
    "    e = torch.round(stddev*torch.randn(N))\n",
    "    e = e.squeeze()\n",
    "    return e.to(torch.int)\n",
    "\n",
    "def uniform(dim, modulus):\n",
    "    return torch.randint(modulus, size = (dim,))\n",
    "\n",
    "def polymult(a, b, dim, modulus):\n",
    "    res = torch.zeros(dim).to(torch.int)\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            if i >= j:\n",
    "                res[i] += a[j]*b[i-j]\n",
    "                res[i] %= modulus\n",
    "            else:\n",
    "                res[i] -= a[j]*b[i-j] # Q - x mod Q = -x\n",
    "                res[i] %= modulus\n",
    "\n",
    "    res %= modulus\n",
    "    return res\n",
    "\n",
    "root_powers = torch.arange(N//2).to(torch.complex128)\n",
    "root_powers = torch.exp((1j*math.pi/N)*root_powers)\n",
    "\n",
    "root_powers_inv = torch.arange(0,-N//2,-1).to(torch.complex128)\n",
    "root_powers_inv = torch.exp((1j*math.pi/N)*root_powers_inv)\n",
    "\n",
    "def negacyclic_fft(a, N, Q):\n",
    "    acomplex = a.to(torch.complex128)\n",
    "\n",
    "    a_precomp = (acomplex[...,:N//2] + 1j * acomplex[..., N//2:]) * root_powers\n",
    "\n",
    "    return torch.fft.fft(a_precomp)\n",
    "\n",
    "def negacyclic_ifft(A, N, Q):\n",
    "    b = torch.fft.ifft(A)\n",
    "    b *= root_powers_inv\n",
    "\n",
    "    a = torch.cat((b.real, b.imag), dim=-1)\n",
    "\n",
    "    aint = a.to(torch.int32)\n",
    "    # only when Q is a power-of-two\n",
    "    aint &= Q-1\n",
    "\n",
    "    return aint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate two keys\n",
    "s1 = keygen(N)\n",
    "s2 = keygen(N)\n",
    "\n",
    "s1fft = negacyclic_fft(s1, N, Q)\n",
    "s2fft = negacyclic_fft(s2, N, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an RLWE encryption of message\n",
    "def encrypt_to_fft(m, sfft):\n",
    "    ct = torch.stack([errgen(stddev, N), uniform(N, Q)])\n",
    "    ctfft = negacyclic_fft(ct, N, Q)\n",
    "\n",
    "    ctfft[0] += -ctfft[1]*sfft + negacyclic_fft(m, N, Q)\n",
    "\n",
    "    return ctfft\n",
    "\n",
    "def normalize(v, logQ):\n",
    "    # same as follows but no branch\n",
    "    \"\"\"\n",
    "    if v > Q//2:\n",
    "        v -= Q\n",
    "    \"\"\"\n",
    "    # vmod Q when Q is a power-of-two\n",
    "    Q = (1 << logQ)\n",
    "    v &= Q-1\n",
    "    # get msb\n",
    "    msb = (v & Q//2) >> (logQ - 1)\n",
    "    v -= (Q) * msb\n",
    "    return v\n",
    "\n",
    "def decrypt_from_fft(ctfft, sfft):\n",
    "    return normalize(negacyclic_ifft(ctfft[0] + ctfft[1]*sfft, N, Q), logQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000000,       0,       0,  ...,       0,       0,       0],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.zeros((N), dtype=torch.int32)\n",
    "m[0] = 1000000\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([999997,     -3,     -1,  ...,     -1,      1,      0],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctfft = encrypt_to_fft(m, s1fft)\n",
    "mdec = decrypt_from_fft(ctfft, s1fft)\n",
    "mdec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot decrypt mdec with s2, as the secret key is different. It should look like a random value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-30775409,  29496231,  58264218,  ...,  30844357, -58722876,\n",
       "         -5122044], dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdec_wrong = decrypt_from_fft(ctfft, s2fft)\n",
    "mdec_wrong"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to transform ct as a ciphertext of the same message but with different key s2 *without decryption*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Gadget decomposition\n",
    "\n",
    "We define *gadget decomposition* $h$ corresponding to gadget vector $\\vec{g} = (g_0, g_1, \\dots, g_{d-1})$ as follows.\n",
    "$$\n",
    "h: \\mathbb{Z} \\longmapsto \\mathbb{Z}^d\n",
    "$$\n",
    "$$\n",
    "||h(a)|| < B, \\left< h(a), \\vec{g}\\right> = a,\n",
    "$$\n",
    "where B is a upper bound.\n",
    "\n",
    "Also, we can naturally extend it to $\\mathcal{R}$ and $\\mathbb{Z}^n$.\n",
    "\n",
    "For example, a number $77 = 0\\text{b}01001101$ can be decomposed to $(1,0,1,1,0,0,1,0)$ when $\\vec{g} = (1, 2, \\dots, 2^7)$ and $B=2$\n",
    "\n",
    "Otherwise, it can also be decomposed to $(1,3,0,1)$ when $\\vec{g} = (1, 4, 4^2, 4^3)$, and $B=4$ here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can do a *approximate gadget decomposition* where $\\left< h(a), \\vec{g}\\right> \\approx a$, i.e., $\\left< h(a), \\vec{g}\\right>$ is not exactly the same but similar to $a$.\n",
    "\n",
    "We first set d and B satisfying $B^{d} \\le Q \\le B^{d+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use B-ary decomposition, i.e., cut digits by logB bits\n",
    "d = 4\n",
    "logB = 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shift by amount of decomp_shit and cut `logB` MSBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3],\n",
       "        [ 9],\n",
       "        [15],\n",
       "        [21]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomp_shift = logQ - logB*torch.arange(d,0,-1).view(d,1)\n",
    "decomp_shift\n",
    "\n",
    "mask = (1 << logB) - 1\n",
    "\n",
    "decomp_shift"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the gadget vector, \n",
    "$$\n",
    "\\vec{g} = (B, B^2, \\dots, B^{d-1})\n",
    "$$\n",
    "is given as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      8],\n",
       "        [    512],\n",
       "        [  32768],\n",
       "        [2097152]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gvector = 1 << decomp_shift\n",
    "gvector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decomposition function handles both RLWE' and RGSW case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(a):\n",
    "    \n",
    "    assert len(a.size()) <= 2\n",
    "    # for RLWE'\n",
    "    if len(a.size()) == 1:\n",
    "        res = (a.unsqueeze(0) >> decomp_shift.view(d, 1)) & mask\n",
    "        return res\n",
    "    # for RGSW\n",
    "    elif len(a.size()) == 2:\n",
    "        res = (a.unsqueeze(0) >> decomp_shift.view(d, 1, 1)) & mask\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 94193827,  51940049,  84661416,  21719618,  41322980,  35156455,\n",
       "         49498149, 116411239,  20979234,  63728665])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = uniform(N, Q)\n",
    "a[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the decomposed vector always has value less than $B = 2^6 = 64$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, 26, 21,  ...,  3, 48, 60],\n",
       "        [36,  5, 42,  ..., 33, 22, 10],\n",
       "        [58, 49, 23,  ..., 57, 49, 34],\n",
       "        [44, 24, 40,  ..., 12, 23, 30]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = decompose(a)\n",
    "# see all values are smaller than 2^6 = 64\n",
    "da"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See $<h(a), \\vec{g}> \\approx a$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([94193824, 51940048, 84661416,  ..., 27050520, 49851776, 64034272])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#composition is inner product, see it is similar to a\n",
    "torch.sum(da * gvector, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([94193827, 51940049, 84661416,  ..., 27050525, 49851783, 64034279])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 0, 2, 4, 7, 5, 7, 2, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = a - torch.sum(da * gvector, dim = 0)\n",
    "diff %= Q\n",
    "diff = normalize(diff, logQ)\n",
    "diff[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend it to a ciphertext too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:\n",
      " tensor([33554432.,        0.,        0., 33554432.,        0.,        0.,\n",
      "               0.,        0.,        0.,        0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 39737414,  13959872,  92131300,  ...,  15676777,  59094439,\n",
       "          44448668],\n",
       "        [ 81619725, 119691098,  49104517,  ...,   7291234,   4035796,\n",
       "         130607505]], dtype=torch.int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.zeros(N)\n",
    "m[0] = Q//4\n",
    "m[3] = Q//4\n",
    "print(\"m:\\n\", m[:10])\n",
    "ctfft = encrypt_to_fft(m, s1fft)\n",
    "ct = negacyclic_ifft(ctfft, N, Q)\n",
    "ct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see the message part in the next subsection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 39737408,  13959872,  92131296,  ...,  15676776,  59094432,\n",
       "          44448664],\n",
       "        [ 81619720, 119691096,  49104512,  ...,   7291232,   4035792,\n",
       "         130607504]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctnew = torch.sum(decompose(ct) * gvector.view(d, 1, 1), dim = 0)\n",
    "ctnew"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decrypt it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:\n",
      " tensor([33554432.,        0.,        0., 33554432.,        0.,        0.,\n",
      "               0.,        0.,        0.,        0.])\n",
      "dm:\n",
      " tensor([33556360,     1840,     1849, 33556272,     1968,     1873,     1832,\n",
      "            1904,     1904,     1968], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "ctnewfft = negacyclic_fft(ctnew, N, Q)\n",
    "\n",
    "dm = decrypt_from_fft(ctnewfft, s1fft)[:10]\n",
    "print(\"m:\\n\", m[:10])\n",
    "print(\"dm:\\n\", dm[:10])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.RLWE' Ciphertext and key switching keys.\n",
    "\n",
    "We can make a tuple of RLWE ciphertexts corresponding to a gadget vector $\\vec{g} = (g_0, \\dots, g_{d-1})$, and call it RLWE'.\n",
    "$$\n",
    "RLWE'( \\boldsymbol{s} ) =\\left( RLWE(g_0 \\boldsymbol{s}), RLWE(g_1 \\boldsymbol{s}), \\dots, RLWE(g_{d-1} \\boldsymbol{s})  \\right) \n",
    "\\in \\mathcal{R}^{d\\times N}\n",
    "$$\n",
    "\n",
    "Then the inner product between $h(\\boldsymbol{m})$ and $RLWE'( \\boldsymbol{s} )$ will give us RLWE (not RLWE'!!!) encryption of $\\boldsymbol{m\\cdot s}$, $RLWE(\\boldsymbol{m \\cdot s})$.\n",
    "The correctness can be seen as follows:\n",
    "$$\n",
    "\\left<(\\boldsymbol{m}_0, \\dots, \\boldsymbol{m}_{d-1}),  \\left( RLWE(g_0 \\boldsymbol{s}), \\dots, RLWE(g_{d-1} \\boldsymbol{s})  \\right) \\right>\n",
    "= \\sum_{i = 0}^{d-1} (\\boldsymbol{m}_i \\cdot RLWE(g_i \\boldsymbol{s}))\n",
    "= RLWE( \\sum_{i = 0}^{d-1} (\\boldsymbol{m}_i \\cdot g_i \\boldsymbol{s}))\n",
    "= RLWE( \\sum_{i = 0}^{d-1} (\\boldsymbol{m} \\cdot \\boldsymbol{s}))\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2.1. Error analysis (why RLWE'?)\n",
    "\n",
    "We can also get a ciphertext of $RLWE(\\boldsymbol{m}\\boldsymbol{s})$ by multiplying $\\boldsymbol{m}$ to each element  of $RLWE(\\boldsymbol{s})$.\n",
    "In other words, $(\\boldsymbol{m} \\cdot \\boldsymbol{b}, \\boldsymbol{m}\\cdot \\boldsymbol{a})$ is $RLWE(\\boldsymbol{m}\\boldsymbol{s})$, \n",
    "where $RLWE(\\boldsymbol{s}) = (\\boldsymbol{b}, \\boldsymbol{a})$.\n",
    "\n",
    "**Naive multiplication**\n",
    "\n",
    "However, an error $\\boldsymbol{e}$ is contained in $RLWE(\\boldsymbol{s})$, so the decryption $\\boldsymbol{b} + \\boldsymbol{a} \\cdot  \\boldsymbol{s}$ will be given as \n",
    "$$ \n",
    "\\boldsymbol{s} +  \\boldsymbol{e}.\n",
    "$$\n",
    "Thus, the decryption of $RLWE(\\boldsymbol{ms}) = (\\boldsymbol{mb}, \\boldsymbol{ma})$ results in $ \\boldsymbol{ms} +  \\boldsymbol{me}$.\n",
    "\n",
    "**Multiplication using RLWE'**\n",
    "\n",
    "It is okay when $\\boldsymbol{m}$ is small (so it is used to multiply a small constant), but we usually need to to multiply $\\boldsymbol{m}$ uniformly sampled in $\\mathbb{Z}_Q$.\n",
    "In this case, the error variance will be $O(Q^2 \\sigma^2)$, where $\\sigma$ is variance of $\\boldsymbol{e}$, and it overwhelms the message.\n",
    "\n",
    "Instead, if we use the RLWE' product, each ciphertext $RLWE'(g_i \\boldsymbol{s})$ is multiplied by $\\boldsymbol{m}_i$, whose size is smaller than $B$.\n",
    "Assuming they are uniformly distributed, the error variance of $RLWE'(\\boldsymbol{m}_i g_i \\boldsymbol{s})$ should be $B^2/12 \\sigma^2$.\n",
    "Adding $d$ of them, the error variance is  \n",
    "$$\n",
    "dB^2/12 \\sigma^2,\n",
    "$$ \n",
    "where $B = Q^{1/d} \\ll Q$.\n",
    "\n",
    "Naive multiplication is *infeasible* when $\\boldsymbol{m}$ is large, which is exactly the case we want. \n",
    "So, we need RLWE' ciphertext (as key) and multiplication using it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encrypt a key using RLWE' ciphertext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [105131693,  43028727,  59218047,  ...,  23781605,  83649302,\n",
       "           61094060]],\n",
       "\n",
       "        [[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [ 98837028,  22036715,  31255247,  ...,  60782403,  44504675,\n",
       "            6568757]],\n",
       "\n",
       "        [[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [105422446, 103038924,  36428025,  ...,  57190672,  22163141,\n",
       "           72082054]],\n",
       "\n",
       "        [[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [ 93398305,  29353121, 126119049,  ...,   2045833, 133602593,\n",
       "           63093644]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it has a dimension of d, 2, N\n",
    "rlwep = torch.zeros(d, 2, N, dtype=torch.int32)\n",
    "\n",
    "# generate the 'a' part\n",
    "rlwep[:, 1, :] = torch.randint(Q, size = (d, N), dtype= torch.int32)\n",
    "\n",
    "rlwep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[       -1,         1,         2,  ...,         5,         0,\n",
       "                 -3],\n",
       "         [105131693,  43028727,  59218047,  ...,  23781605,  83649302,\n",
       "           61094060]],\n",
       "\n",
       "        [[        5,        -5,         1,  ...,         1,        -2,\n",
       "                 -3],\n",
       "         [ 98837028,  22036715,  31255247,  ...,  60782403,  44504675,\n",
       "            6568757]],\n",
       "\n",
       "        [[        4,        -5,        -7,  ...,        -4,         3,\n",
       "                  2],\n",
       "         [105422446, 103038924,  36428025,  ...,  57190672,  22163141,\n",
       "           72082054]],\n",
       "\n",
       "        [[        2,        -1,        -6,  ...,         8,         4,\n",
       "                 -4],\n",
       "         [ 93398305,  29353121, 126119049,  ...,   2045833, 133602593,\n",
       "           63093644]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add error on b\n",
    "rlwep[:, 0, :] = torch.round(stddev * torch.randn(size = (d, N)))\n",
    "\n",
    "rlwep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[134217727,         1,         2,  ...,         5,         0,\n",
       "          134217725],\n",
       "         [105131693,  43028727,  59218047,  ...,  23781605,  83649302,\n",
       "           61094060]],\n",
       "\n",
       "        [[        5, 134217723,         1,  ...,         1, 134217726,\n",
       "          134217725],\n",
       "         [ 98837028,  22036715,  31255247,  ...,  60782403,  44504675,\n",
       "            6568757]],\n",
       "\n",
       "        [[        4, 134217723, 134217721,  ..., 134217724,         3,\n",
       "                  2],\n",
       "         [105422446, 103038924,  36428025,  ...,  57190672,  22163141,\n",
       "           72082054]],\n",
       "\n",
       "        [[        2, 134217727, 134217722,  ...,         8,         4,\n",
       "          134217724],\n",
       "         [ 93398305,  29353121, 126119049,  ...,   2045833, 133602593,\n",
       "           63093644]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# following is equal to rlwep %= Q, but a faster version\n",
    "rlwep &= (Q-1)\n",
    "\n",
    "rlwep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do fft for easy a*s\n",
    "rlwepfft = negacyclic_fft(rlwep, N, Q)\n",
    "\n",
    "# now b = -a*s2 + e\n",
    "rlwepfft[:, 0, :] -= rlwepfft[:, 1, :] * s2fft.view(1,N//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[105703223,  46420690,  53786687,  ..., 102437439,  49696800,\n",
       "           88625034],\n",
       "         [105131693,  43028727,  59218046,  ...,  23781604,  83649302,\n",
       "           61094060]],\n",
       "\n",
       "        [[ 82051802,  19886463,   1014332,  ..., 120222834,  79401825,\n",
       "          128812660],\n",
       "         [ 98837028,  22036715,  31255247,  ...,  60782403,  44504675,\n",
       "            6568757]],\n",
       "\n",
       "        [[ 41358369,   8097865, 128448284,  ..., 101864579,  30638379,\n",
       "           64260024],\n",
       "         [105422446, 103038924,  36428024,  ...,  57190672,  22163141,\n",
       "           72082054]],\n",
       "\n",
       "        [[ 37733434,  34789102, 107132699,  ...,  58341145,  41061950,\n",
       "           45352168],\n",
       "         [ 93398305,  29353121, 126119048,  ...,   2045832, 133602593,\n",
       "           63093644]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return back to R_Q\n",
    "rlwepifft = negacyclic_ifft(rlwepfft, N, Q)\n",
    "\n",
    "rlwepifft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      8,       0,       8,  ...,       0,       8,       0],\n",
       "        [    512,       0,     512,  ...,       0,     512,       0],\n",
       "        [  32768,       0,   32768,  ...,       0,   32768,       0],\n",
       "        [2097152,       0, 2097152,  ...,       0, 2097152,       0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add decomposition of s1* vec{g}\n",
    "gs1 = gvector * s1\n",
    "\n",
    "gs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlwepifft[:, 0, :] += gs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksk = negacyclic_fft(rlwepifft, N, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksk.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 39737414,  13959872,  92131300,  ...,  15676777,  59094439,\n",
       "          44448668],\n",
       "        [ 81619725, 119691098,  49104517,  ...,   7291234,   4035796,\n",
       "         130607505]], dtype=torch.int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([33554427,        0,        3, 33554432,        0,       -3,        0,\n",
      "              -5,       -1,        1], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "mdec = decrypt_from_fft(ctfft, s1fft)\n",
    "print(mdec[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = decompose(ct[1])\n",
    "dctfft = negacyclic_fft(dct, N, Q)\n",
    "dctfft.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 81619725, 119691098,  49104517,  ...,   7291234,   4035796,\n",
      "        130607505], dtype=torch.int32)\n",
      "tensor([ 81619720, 119691096,  49104512,  ...,   7291232,   4035792,\n",
      "        130607504])\n"
     ]
    }
   ],
   "source": [
    "print(ct[1])\n",
    "print(torch.sum(dct*gvector, dim = 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is\n",
    "$$\n",
    "a \\odot RLWE'_{s2}(s1) = RLWE_{s2}(a \\cdot s1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 512]),\n",
       " tensor([[-3.6756e+15-6.4560e+13j, -4.0228e+14+4.5322e+11j,\n",
       "          -7.3409e+13+4.6276e+12j,  ...,\n",
       "          -2.4512e+13-2.4045e+12j, -5.0447e+13+3.9861e+12j,\n",
       "          -1.4421e+14+7.1230e+12j],\n",
       "         [-3.5640e+15-2.0938e+13j, -3.9533e+14-1.4981e+12j,\n",
       "          -7.8482e+13+6.2964e+12j,  ...,\n",
       "          -2.0769e+13-2.4418e+12j, -5.8814e+13+7.9083e+12j,\n",
       "          -1.3519e+14+2.3577e+13j]], dtype=torch.complex128))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodfft = dctfft.view(d, 1, N//2) * ksk\n",
    "prodsumfft = torch.sum(prodfft, dim = 0)\n",
    "\n",
    "prodsumfft.size(), prodsumfft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding $b$ to above, we get\n",
    "$$\n",
    "RLWE_{\\boldsymbol{s2}}(\\boldsymbol{a} \\cdot \\boldsymbol{s1}) + (\\boldsymbol{b}, \\boldsymbol{0}) = RLWE_{\\boldsymbol{s2}}(\\boldsymbol{a} \\cdot \\boldsymbol{s1} + \\boldsymbol{b})\n",
    "= RLWE_{\\boldsymbol{s2}}(\\boldsymbol{m} )\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodsumfft[0] += ctfft[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can decrypt using the switched key $s_2$.\n",
    "\n",
    "Check if the decryption is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:\n",
      " tensor([33554432.,        0.,        0., 33554432.,        0.,        0.,\n",
      "               0.,        0.,        0.,        0.])\n",
      "decrypted:\n",
      " tensor([34075874,   589722,   652463, 34230423,   729336,   798338,   854322,\n",
      "          885747,   950882,  1012988], dtype=torch.int32)\n",
      "decrypted (scaled to 1):\n",
      " tensor([1.0155, 0.0176, 0.0194, 1.0201, 0.0217, 0.0238, 0.0255, 0.0264, 0.0283,\n",
      "        0.0302])\n"
     ]
    }
   ],
   "source": [
    "mks = decrypt_from_fft(prodsumfft, s2fft)\n",
    "print(\"m:\\n\",m[:10])\n",
    "print(\"decrypted:\\n\",mks[:10])\n",
    "print(\"decrypted (scaled to 1):\\n\",mks[:10]/(Q//4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
