{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gadget decomposition\n",
    "\n",
    "**GOAL:** for a given polynomial $\\boldsymbol{a}$ and an encryption $\\textsf{RLWE}(m)$ (or something similar to it), find $\\textsf{RLWE}(\\boldsymbol{a}\\cdot \\boldsymbol{m})$, with small noise.\n",
    "\n",
    "Gadget decomposition and $RLWE'$ technique allows us to multiply ciphertext to a *large* constant with *small* noise increment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RLWE' is usually used for the key switching. We make an example of key switching from s1 to s2 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from previous lecturenote\n",
    "import torch\n",
    "import math\n",
    "\n",
    "stddev = 3.2\n",
    "logQ = 27\n",
    "\n",
    "N = 2**10\n",
    "Q = 2**logQ\n",
    "\n",
    "\n",
    "def keygen(dim):\n",
    "    return torch.randint(2, size = (dim,))\n",
    "\n",
    "def errgen(stddev):\n",
    "    e = torch.round(stddev*torch.randn(1))\n",
    "    e = e.squeeze()\n",
    "    return e.to(torch.int)\n",
    "\n",
    "def errgen(stddev, N):\n",
    "    e = torch.round(stddev*torch.randn(N))\n",
    "    e = e.squeeze()\n",
    "    return e.to(torch.int)\n",
    "\n",
    "def uniform(dim, modulus):\n",
    "    return torch.randint(modulus, size = (dim,))\n",
    "\n",
    "def polymult(a, b, dim, modulus):\n",
    "    res = torch.zeros(dim).to(torch.int)\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            if i >= j:\n",
    "                res[i] += a[j]*b[i-j]\n",
    "                res[i] %= modulus\n",
    "            else:\n",
    "                res[i] -= a[j]*b[i-j] # Q - x mod Q = -x\n",
    "                res[i] %= modulus\n",
    "\n",
    "    res %= modulus\n",
    "    return res\n",
    "\n",
    "root_powers = torch.arange(N//2).to(torch.complex128)\n",
    "root_powers = torch.exp((1j*math.pi/N)*root_powers)\n",
    "\n",
    "root_powers_inv = torch.arange(0,-N//2,-1).to(torch.complex128)\n",
    "root_powers_inv = torch.exp((1j*math.pi/N)*root_powers_inv)\n",
    "\n",
    "def negacyclic_fft(a, N, Q):\n",
    "    acomplex = a.to(torch.complex128)\n",
    "\n",
    "    a_precomp = (acomplex[...,:N//2] + 1j * acomplex[..., N//2:]) * root_powers\n",
    "\n",
    "    return torch.fft.fft(a_precomp)\n",
    "\n",
    "def negacyclic_ifft(A, N, Q):\n",
    "    b = torch.fft.ifft(A)\n",
    "    b *= root_powers_inv\n",
    "\n",
    "    a = torch.cat((b.real, b.imag), dim=-1)\n",
    "\n",
    "    aint = a.to(torch.int32)\n",
    "    # only when Q is a power-of-two\n",
    "    aint &= Q-1\n",
    "\n",
    "    return aint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate two keys\n",
    "s1 = keygen(N)\n",
    "s2 = keygen(N)\n",
    "\n",
    "s1fft = negacyclic_fft(s1, N, Q)\n",
    "s2fft = negacyclic_fft(s2, N, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an RLWE encryption of message\n",
    "def encrypt_to_fft(m, sfft):\n",
    "    ct = torch.stack([errgen(stddev, N), uniform(N, Q)])\n",
    "    ctfft = negacyclic_fft(ct, N, Q)\n",
    "\n",
    "    ctfft[0] += -ctfft[1]*sfft + negacyclic_fft(m, N, Q)\n",
    "\n",
    "    return ctfft\n",
    "\n",
    "def decrypt_from_fft(ctfft, sfft):\n",
    "    return negacyclic_ifft(ctfft[0] + ctfft[1]*sfft, N, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000000,       0,       0,  ...,       0,       0,       0],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.zeros((N), dtype=torch.int32)\n",
    "m[0] = 1000000\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   999999,         1,         1,  ...,         0, 134217725,\n",
       "        134217727], dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctfft = encrypt_to_fft(m, s1fft)\n",
    "mdec = decrypt_from_fft(ctfft, s1fft)\n",
    "mdec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot decrypt mdec with s2, as the secret key is different. It should look like a random value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([94206457, 32622688, 21222813,  ..., 89645965, 13428919, 65218450],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdec_wrong = decrypt_from_fft(ctfft, s2fft)\n",
    "mdec_wrong"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to transform ct as a ciphertext of the same message but with different key s2 *without decryption*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Gadget decomposition\n",
    "\n",
    "We define *gadget decomposition* $h$ corresponding to gadget vector $\\vec{g} = (g_0, g_1, \\dots, g_{d-1})$ as follows.\n",
    "$$\n",
    "h: \\mathbb{Z} \\longmapsto \\mathbb{Z}^d\n",
    "$$\n",
    "$$\n",
    "||h(a)|| < B, \\left< h(a), \\vec{g}\\right> = a,\n",
    "$$\n",
    "where B is a upper bound.\n",
    "\n",
    "Also, we can naturally extend it to $\\mathcal{R}$ and $\\mathbb{Z}^n$.\n",
    "\n",
    "For example, a number $77 = 0\\text{b}01001101$ can be decomposed to $(0,1,0,0,1,1,0,1)$ when $\\vec{g} = (2^7, 2^6, \\dots, 1)$ and $B=2$\n",
    "\n",
    "Otherwise, it can also be decomposed to $(1,0,3,1)$ when $\\vec{g} = (4^3, 4^2, 4, 1)$, and $B=4$ here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can do a *approximate gadget decomposition* where $\\left< h(a), \\vec{g}\\right> \\approx a$, i.e., $\\left< h(a), \\vec{g}\\right>$ is not exactly the same but similar to $a$.\n",
    "\n",
    "We first set d and B satisfying $B^{d} \\le Q \\le B^{d+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use B-ary decomposition, i.e., cut digits by logB bits\n",
    "d = 3\n",
    "logB = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_shift = logQ - logB*torch.arange(1,d+1).view(d,1)\n",
    "decomp_shift\n",
    "\n",
    "mask = (1<< logB)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(a):\n",
    "\n",
    "    assert len(a.size()) <= 2\n",
    "\n",
    "    if len(a.size()) == 1:\n",
    "        return (a.unsqueeze(0) >> decomp_shift.view(d, 1)) & mask\n",
    "    elif len(a.size()) == 2:\n",
    "        return (a.unsqueeze(0) >> decomp_shift.view(d, 1, 1)) & mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1048576],\n",
       "        [   8192],\n",
       "        [     64]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gvector = 1<<decomp_shift\n",
    "gvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97657358,  85445077,  29105743,  ..., 127586060,  93580405,\n",
       "         44880300])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = uniform(N, Q)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 93,  81,  27,  ..., 121,  89,  42],\n",
       "        [ 17,  62,  96,  ...,  86,  31, 102],\n",
       "        [  8,  39, 121,  ...,  60,  49,  70]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = decompose(a)\n",
    "# see all values are smaller than 2^7 = 128\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97657344,  85445056,  29105728,  ..., 127586048,  93580352,\n",
       "         44880256])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#composition is inner product, see it is similar to a\n",
    "torch.sum(da * gvector, dim = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend it to a ciphertext too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 53410785,  43055478,  73744037,  ..., 103529846,  82593721,\n",
       "         115845510],\n",
       "        [ 33853395,  17871358, 103050552,  ...,  71641821,  69220000,\n",
       "          65527806]], dtype=torch.int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctfft = encrypt_to_fft(m, s1fft)\n",
    "ct = negacyclic_ifft(ctfft, N, Q)\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 53410752,  43055424,  73744000,  ..., 103529792,  82593664,\n",
       "         115845504],\n",
       "        [ 33853376,  17871296, 103050496,  ...,  71641792,  69219968,\n",
       "          65527744]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(decompose(ct) * gvector.view(d, 1, 1), dim = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.RLWE' Ciphertext and key switching keys.\n",
    "\n",
    "We can make a tuple of RLWE ciphertexts corresponding to a gadget vector $\\vec{g} = (g_0, \\dots, g_{d-1})$, and call it RLWE'.\n",
    "$$\n",
    "RLWE'( \\boldsymbol{s} ) =\\left( RLWE(g_0 \\boldsymbol{s}), RLWE(g_1 \\boldsymbol{s}), \\dots, RLWE(g_{d-1} \\boldsymbol{s})  \\right) \n",
    "\\in \\mathcal{R}^{d\\times N}\n",
    "$$\n",
    "\n",
    "Then the inner product between $h(\\boldsymbol{m})$ and $RLWE'( \\boldsymbol{s} )$ will give us RLWE (not RLWE') encryption of $\\boldsymbol{m}$, $RLWE(\\boldsymbol{a \\cdot s})$.\n",
    "The correctness can be seen as follows:\n",
    "$$\n",
    "\\left<(\\boldsymbol{m}_0, \\dots, \\boldsymbol{m}_{d-1}),  \\left( RLWE(g_0 \\boldsymbol{s}), \\dots, RLWE(g_{d-1} \\boldsymbol{s})  \\right) \\right>\n",
    "= \\sum_{i = 0}^{d-1} (\\boldsymbol{m}_i \\cdot RLWE(g_i \\boldsymbol{s}))\n",
    "= RLWE( \\sum_{i = 0}^{d-1} (\\boldsymbol{m}_i \\cdot g_i \\boldsymbol{s}))\n",
    "= RLWE( \\sum_{i = 0}^{d-1} (\\boldsymbol{m} \\cdot \\boldsymbol{s}))\n",
    "$$\n",
    "\n",
    "### 2.2.1. Error analysis (why RLWE'?)\n",
    "\n",
    "We can also get a ciphertext of $RLWE(\\boldsymbol{m}\\boldsymbol{s})$ by multiplying $\\boldsymbol{m}$ to each element of $RLWE(\\boldsymbol{s})$.\n",
    "In other words, $(\\boldsymbol{m} \\cdot \\boldsymbol{b}, \\boldsymbol{m}\\cdot \\boldsymbol{a})$ is $RLWE(\\boldsymbol{m}\\boldsymbol{s})$, \n",
    "where $RLWE(\\boldsymbol{s}) = (\\boldsymbol{b}, \\boldsymbol{a})$.\n",
    "\n",
    "**Naive multiplication**\n",
    "\n",
    "However, an error $\\boldsymbol{e}$ is contained in $RLWE(\\boldsymbol{s})$, so the decryption $\\boldsymbol{b} + \\boldsymbol{a} \\cdot  \\boldsymbol{s}$ will be given as \n",
    "$$ \n",
    "\\boldsymbol{s} +  \\boldsymbol{e}.\n",
    "$$\n",
    "Thus, the decryption of $RLWE(\\boldsymbol{ms}) = (\\boldsymbol{mb}, \\boldsymbol{ma})$ results in $ \\boldsymbol{ms} +  \\boldsymbol{me}$.\n",
    "\n",
    "**Multiplication using RLWE'**\n",
    "\n",
    "It is okay when $\\boldsymbol{m}$ is small (so it is used to multiply a small constant), but we usually need to to multiply $\\boldsymbol{m}$ uniformly sampled in $\\mathbb{Z}_Q$.\n",
    "In this case, the error variance will be $Q^2 \\sigma^2$, where $\\sigma$ is variance of $\\boldsymbol{e}$, and it overwhelms the message.\n",
    "\n",
    "Instead, if we use the RLWE' product, each ciphertext $RLWE'(g_i \\boldsymbol{s})$ is multiplied by $\\boldsymbol{m}_i$, whose size is smaller than $B$.\n",
    "Assuming they are uniformly distributed, the error variance of $RLWE'(\\boldsymbol{m}_i g_i \\boldsymbol{s})$ should be $B^2/12 \\sigma^2$.\n",
    "Adding $d$ of them, the error variance is  \n",
    "$$\n",
    "dB^2/12 \\sigma^2,\n",
    "$$ \n",
    "where $B = Q^{1/d} \\ll Q$.\n",
    "\n",
    "Naive multiplication is *infeasible* when $\\boldsymbol{m}$ is large, which is exactly the case we want. \n",
    "So, we need RLWE' ciphertext and multiplication using it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encrypt key using RLWE' ciphertext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [124659440,  94520205,  71042207,  ..., 110570277,   3546280,\n",
       "          124776653]],\n",
       "\n",
       "        [[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [ 19101960,   5690381,  27804331,  ...,  46262763,  57761828,\n",
       "           71623088]],\n",
       "\n",
       "        [[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [ 12979970,  65446211, 110722805,  ..., 116226067,  47933314,\n",
       "           77185437]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlwep = torch.zeros(d, 2, N, dtype=torch.int32)\n",
    "\n",
    "# generate a part\n",
    "rlwep[:, 1, :] = torch.randint(Q, size = (d, N), dtype= torch.int32)\n",
    "\n",
    "rlwep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[       -1,        -2,        10,  ...,         3,        -1,\n",
       "                  5],\n",
       "         [124659440,  94520205,  71042207,  ..., 110570277,   3546280,\n",
       "          124776653]],\n",
       "\n",
       "        [[        2,        -1,         5,  ...,        -1,         0,\n",
       "                 -5],\n",
       "         [ 19101960,   5690381,  27804331,  ...,  46262763,  57761828,\n",
       "           71623088]],\n",
       "\n",
       "        [[       -7,        -2,         4,  ...,         4,        -1,\n",
       "                  3],\n",
       "         [ 12979970,  65446211, 110722805,  ..., 116226067,  47933314,\n",
       "           77185437]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add error on b\n",
    "rlwep[:, 0, :] = torch.round(stddev * torch.randn(size = (d, N)))\n",
    "rlwep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do fft for easy a*s\n",
    "rlwepfft = negacyclic_fft(rlwep, N, Q)\n",
    "\n",
    "# now b = -a*s2 + e\n",
    "rlwepfft[:, 0, :] -= rlwepfft[:, 1, :] * s2fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[120516150,  62334107,  89060741,  ...,  95901350,  72683104,\n",
       "           58747394],\n",
       "         [124659440,  94520205,  71042206,  ..., 110570277,   3546280,\n",
       "          124776653]],\n",
       "\n",
       "        [[ 32846998, 116461100,  25032157,  ..., 116260390,  18385891,\n",
       "           19095183],\n",
       "         [ 19101960,   5690380,  27804330,  ...,  46262763,  57761828,\n",
       "           71623088]],\n",
       "\n",
       "        [[125341286, 101676018,  15652642,  ...,  27402630, 111753956,\n",
       "           33526242],\n",
       "         [ 12979970,  65446210, 110722805,  ..., 116226067,  47933314,\n",
       "           77185437]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return back to R_Q\n",
    "rlwepifft = negacyclic_ifft(rlwepfft, N, Q)\n",
    "rlwepifft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1024])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add decomposition of s1* vec{g}\n",
    "gs1 = gvector * s1\n",
    "\n",
    "gs1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlwepifft[:, 0, :] += gs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksk = rlwepifft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[121564726,  63382683,  89060741,  ...,  95901350,  73731680,\n",
       "           59795970],\n",
       "         [124659440,  94520205,  71042206,  ..., 110570277,   3546280,\n",
       "          124776653]],\n",
       "\n",
       "        [[ 32855190, 116469292,  25032157,  ..., 116260390,  18394083,\n",
       "           19103375],\n",
       "         [ 19101960,   5690380,  27804330,  ...,  46262763,  57761828,\n",
       "           71623088]],\n",
       "\n",
       "        [[125341350, 101676082,  15652642,  ...,  27402630, 111754020,\n",
       "           33526306],\n",
       "         [ 12979970,  65446210, 110722805,  ..., 116226067,  47933314,\n",
       "           77185437]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 53410785,  43055478,  73744037,  ..., 103529846,  82593721,\n",
       "         115845510],\n",
       "        [ 33853395,  17871358, 103050552,  ...,  71641821,  69220000,\n",
       "          65527806]], dtype=torch.int32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1000222,       205,       223,  ..., 134217515, 134217506,\n",
      "        134217501], dtype=torch.int32)\n",
      "tensor([1000222,     205,     223,  ...,    -213,    -222,    -227],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "mdec = decrypt_from_fft(negacyclic_fft(ct, N, Q), s1fft)\n",
    "print(mdec)\n",
    "normalize(mdec, Q)\n",
    "print(mdec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000222,     205,     223,  ...,    -213,    -222,    -227],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1024])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decompose(ct[1]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 1024])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksk.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1024]),\n",
       " tensor([[12969363122,  8878853893, 10418015497,  ..., 12466280880,\n",
       "          14942546763,  9149600252],\n",
       "         [ 5494510750,  6281976295, 13692873598,  ..., 14413273000,\n",
       "           4605814568, 21979334441]]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod = decompose(ct[1]).view(d, 1, N) * ksk\n",
    "prodsum = torch.sum(prod, dim = 0)\n",
    "\n",
    "prodsum.size(), prodsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodfft = negacyclic_fft(prodsum, N, Q)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can decrypt using the switched key $s_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([115243276,  29342566, 110492725,  ...,  57805258,  79197029,\n",
      "         71597867], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "mks = decrypt_from_fft(prodfft, s2fft)\n",
    "print(mks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-18974452,  29342566, -23725003,  ...,  57805258, -55020699,\n",
       "        -62619861], dtype=torch.int32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(mks, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v, Q):\n",
    "    # same as follows but no branch\n",
    "    \"\"\"\n",
    "    if v > Q//2:\n",
    "        v -= Q\n",
    "    \"\"\"\n",
    "    # vmod Q when Q is a power-of-two\n",
    "    v &= Q-1\n",
    "    # get msb\n",
    "    msb = (v & Q//2) >>  (logQ - 1)\n",
    "    v -= (Q) * msb\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
