{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gadget decomposition\n",
    "\n",
    "**GOAL:** for a given polynomial $\\boldsymbol{a}$ and an encryption $\\textsf{RLWE}(m)$ (or something similar to it), find $\\textsf{RLWE}(\\boldsymbol{a}\\cdot \\boldsymbol{m})$, with small noise.\n",
    "\n",
    "Gadget decomposition and $RLWE'$ technique allows us to multiply ciphertext to a *large* constant with *small* noise increment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RLWE' is usually used for the key switching. We make an example of key switching from s1 to s2 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from previous lecturenote\n",
    "import torch\n",
    "import math\n",
    "\n",
    "stddev = 3.2\n",
    "logQ = 27\n",
    "\n",
    "N = 2**10\n",
    "Q = 2**logQ\n",
    "\n",
    "\n",
    "def keygen(dim):\n",
    "    return torch.randint(2, size = (dim,))\n",
    "\n",
    "def errgen(stddev):\n",
    "    e = torch.round(stddev*torch.randn(1))\n",
    "    e = e.squeeze()\n",
    "    return e.to(torch.int)\n",
    "\n",
    "def errgen(stddev, N):\n",
    "    e = torch.round(stddev*torch.randn(N))\n",
    "    e = e.squeeze()\n",
    "    return e.to(torch.int)\n",
    "\n",
    "def uniform(dim, modulus):\n",
    "    return torch.randint(modulus, size = (dim,))\n",
    "\n",
    "def polymult(a, b, dim, modulus):\n",
    "    res = torch.zeros(dim).to(torch.int)\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            if i >= j:\n",
    "                res[i] += a[j]*b[i-j]\n",
    "                res[i] %= modulus\n",
    "            else:\n",
    "                res[i] -= a[j]*b[i-j] # Q - x mod Q = -x\n",
    "                res[i] %= modulus\n",
    "\n",
    "    res %= modulus\n",
    "    return res\n",
    "\n",
    "root_powers = torch.arange(N//2).to(torch.complex128)\n",
    "root_powers = torch.exp((1j*math.pi/N)*root_powers)\n",
    "\n",
    "root_powers_inv = torch.arange(0,-N//2,-1).to(torch.complex128)\n",
    "root_powers_inv = torch.exp((1j*math.pi/N)*root_powers_inv)\n",
    "\n",
    "def negacyclic_fft(a, N, Q):\n",
    "    acomplex = a.to(torch.complex128)\n",
    "\n",
    "    a_precomp = (acomplex[...,:N//2] + 1j * acomplex[..., N//2:]) * root_powers\n",
    "\n",
    "    return torch.fft.fft(a_precomp)\n",
    "\n",
    "def negacyclic_ifft(A, N, Q):\n",
    "    b = torch.fft.ifft(A)\n",
    "    b *= root_powers_inv\n",
    "\n",
    "    a = torch.cat((b.real, b.imag), dim=-1)\n",
    "\n",
    "    aint = a.to(torch.int32)\n",
    "    # only when Q is a power-of-two\n",
    "    aint &= Q-1\n",
    "\n",
    "    return aint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate two keys\n",
    "s1 = keygen(N)\n",
    "s2 = keygen(N)\n",
    "\n",
    "s1fft = negacyclic_fft(s1, N, Q)\n",
    "s2fft = negacyclic_fft(s2, N, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an RLWE encryption of message\n",
    "def encrypt_to_fft(m, sfft):\n",
    "    ct = torch.stack([errgen(stddev, N), uniform(N, Q)])\n",
    "    ctfft = negacyclic_fft(ct, N, Q)\n",
    "\n",
    "    ctfft[0] += -ctfft[1]*sfft + negacyclic_fft(m, N, Q)\n",
    "\n",
    "    return ctfft\n",
    "\n",
    "def normalize(v, logQ):\n",
    "    # same as follows but no branch\n",
    "    \"\"\"\n",
    "    if v > Q//2:\n",
    "        v -= Q\n",
    "    \"\"\"\n",
    "    # vmod Q when Q is a power-of-two\n",
    "    Q = (1 << logQ)\n",
    "    v &= Q-1\n",
    "    # get msb\n",
    "    msb = (v & Q//2) >> (logQ - 1)\n",
    "    v -= (Q) * msb\n",
    "    return v\n",
    "\n",
    "def decrypt_from_fft(ctfft, sfft):\n",
    "    return normalize(negacyclic_ifft(ctfft[0] + ctfft[1]*sfft, N, Q), logQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000000,       0,       0,  ...,       0,       0,       0],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.zeros((N), dtype=torch.int32)\n",
    "m[0] = 1000000\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000003,       0,       1,  ...,       3,      -4,       1],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctfft = encrypt_to_fft(m, s1fft)\n",
    "mdec = decrypt_from_fft(ctfft, s1fft)\n",
    "mdec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot decrypt mdec with s2, as the secret key is different. It should look like a random value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 11712410,  49146338,  22304380,  ..., -67061463,  44753809,\n",
       "         -3073699], dtype=torch.int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdec_wrong = decrypt_from_fft(ctfft, s2fft)\n",
    "mdec_wrong"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to transform ct as a ciphertext of the same message but with different key s2 *without decryption*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Gadget decomposition\n",
    "\n",
    "We define *gadget decomposition* $h$ corresponding to gadget vector $\\vec{g} = (g_0, g_1, \\dots, g_{d-1})$ as follows.\n",
    "$$\n",
    "h: \\mathbb{Z} \\longmapsto \\mathbb{Z}^d\n",
    "$$\n",
    "$$\n",
    "||h(a)|| < B, \\left< h(a), \\vec{g}\\right> = a,\n",
    "$$\n",
    "where B is a upper bound.\n",
    "\n",
    "Also, we can naturally extend it to $\\mathcal{R}$ and $\\mathbb{Z}^n$.\n",
    "\n",
    "For example, a number $77 = 0\\text{b}01001101$ can be decomposed to $(1,0,1,1,0,0,1,0)$ when $\\vec{g} = (1, 2, \\dots, 2^7)$ and $B=2$\n",
    "\n",
    "Otherwise, it can also be decomposed to $(1,3,0,1)$ when $\\vec{g} = (1, 4, 4^2, 4^3)$, and $B=4$ here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can do a *approximate gadget decomposition* where $\\left< h(a), \\vec{g}\\right> \\approx a$, i.e., $\\left< h(a), \\vec{g}\\right>$ is not exactly the same but similar to $a$.\n",
    "\n",
    "We first set d and B satisfying $B^{d} \\le Q \\le B^{d+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use B-ary decomposition, i.e., cut digits by logB bits\n",
    "d = 4\n",
    "logB = 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shift by amount of decomp_shit and cut `logB` MSBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3],\n",
       "        [ 9],\n",
       "        [15],\n",
       "        [21]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomp_shift = logQ - logB*torch.arange(d,0,-1).view(d,1)\n",
    "decomp_shift\n",
    "\n",
    "mask = (1 << logB) - 1\n",
    "\n",
    "decomp_shift"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the gadget vector, \n",
    "$$\n",
    "\\vec{g} = (B, B^2, \\dots, B^{d-1})\n",
    "$$\n",
    "is given as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      8],\n",
       "        [    512],\n",
       "        [  32768],\n",
       "        [2097152]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gvector = 1 << decomp_shift\n",
    "gvector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decomposition function handles both RLWE' and RGSW case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(a):\n",
    "    \n",
    "    assert len(a.size()) <= 2\n",
    "    # for RLWE'\n",
    "    if len(a.size()) == 1:\n",
    "        res = (a.unsqueeze(0) >> decomp_shift.view(d, 1)) & mask\n",
    "        return res\n",
    "    # for RGSW\n",
    "    elif len(a.size()) == 2:\n",
    "        res = (a.unsqueeze(0) >> decomp_shift.view(d, 1, 1)) & mask\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([112837406,  94435928,   2684047,  86305079, 128185452, 106015573,\n",
       "        105584985,  81841074,  18582303,  64143918])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = uniform(N, Q)\n",
    "a[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the decomposed vector always has value less than $B = 2^6 = 64$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[35, 11, 17,  ...,  2,  9, 53],\n",
       "        [33, 61, 58,  ...,  5,  1, 43],\n",
       "        [51,  1, 17,  ..., 58, 35, 36],\n",
       "        [53, 45,  1,  ..., 39, 28, 57]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = decompose(a)\n",
    "# see all values are smaller than 2^6 = 64\n",
    "da"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See $<h(a), \\vec{g}> \\approx a$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([112837400,  94435928,   2684040,  ...,  83692048,  59867720,\n",
       "        120739752])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#composition is inner product, see it is similar to a\n",
    "torch.sum(da * gvector, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([112837406,  94435928,   2684047,  ...,  83692050,  59867721,\n",
       "        120739755])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 0, 7, 7, 4, 5, 1, 2, 7, 6])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = a - torch.sum(da * gvector, dim = 0)\n",
    "diff %= Q\n",
    "diff = normalize(diff, logQ)\n",
    "diff[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend it to a ciphertext too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:\n",
      " tensor([33554432.,        0.,        0., 33554432.,        0.,        0.,\n",
      "               0.,        0.,        0.,        0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 86118725,  22323987,  42856786,  ..., 110045621,  58693276,\n",
       "          28320585],\n",
       "        [123551445, 104439256, 100377657,  ..., 104293947, 116006042,\n",
       "          95227960]], dtype=torch.int32)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.zeros(N)\n",
    "m[0] = Q//4\n",
    "m[3] = Q//4\n",
    "print(\"m:\\n\", m[:10])\n",
    "ctfft = encrypt_to_fft(m, s1fft)\n",
    "ct = negacyclic_ifft(ctfft, N, Q)\n",
    "ct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see the message part in the next subsection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 86118720,  22323984,  42856784,  ..., 110045616,  58693272,\n",
       "          28320584],\n",
       "        [123551440, 104439256, 100377656,  ..., 104293944, 116006040,\n",
       "          95227960]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctnew = torch.sum(decompose(ct) * gvector.view(d, 1, 1), dim = 0)\n",
    "ctnew"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decrypt it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Overflow when unpacking long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[251], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m ctnewfft \u001b[39m=\u001b[39m negacyclic_fft(ctnew, N, Q)\n\u001b[0;32m----> 3\u001b[0m dm \u001b[39m=\u001b[39m decrypt_from_fft(ctnewfft, s1fft)[:\u001b[39m10\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mm:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, m[:\u001b[39m10\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdm:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, dm[:\u001b[39m10\u001b[39m])\n",
      "Cell \u001b[0;32mIn[89], line 25\u001b[0m, in \u001b[0;36mdecrypt_from_fft\u001b[0;34m(ctfft, sfft)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecrypt_from_fft\u001b[39m(ctfft, sfft):\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m normalize(negacyclic_ifft(ctfft[\u001b[39m0\u001b[39;49m] \u001b[39m+\u001b[39;49m ctfft[\u001b[39m1\u001b[39;49m]\u001b[39m*\u001b[39;49msfft, N, Q), Q)\n",
      "Cell \u001b[0;32mIn[89], line 18\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(v, logQ)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m# vmod Q when Q is a power-of-two\u001b[39;00m\n\u001b[1;32m     17\u001b[0m Q \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m<<\u001b[39m logQ)\n\u001b[0;32m---> 18\u001b[0m v \u001b[39m&\u001b[39;49m\u001b[39m=\u001b[39;49m Q\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[39m# get msb\u001b[39;00m\n\u001b[1;32m     20\u001b[0m msb \u001b[39m=\u001b[39m (v \u001b[39m&\u001b[39m Q\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m>>\u001b[39m (logQ \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Overflow when unpacking long"
     ]
    }
   ],
   "source": [
    "ctnewfft = negacyclic_fft(ctnew, N, Q)\n",
    "\n",
    "dm = decrypt_from_fft(ctnewfft, s1fft)[:10]\n",
    "print(\"m:\\n\", m[:10])\n",
    "print(\"dm:\\n\", dm[:10])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.RLWE' Ciphertext and key switching keys.\n",
    "\n",
    "We can make a tuple of RLWE ciphertexts corresponding to a gadget vector $\\vec{g} = (g_0, \\dots, g_{d-1})$, and call it RLWE'.\n",
    "$$\n",
    "RLWE'( \\boldsymbol{s} ) =\\left( RLWE(g_0 \\boldsymbol{s}), RLWE(g_1 \\boldsymbol{s}), \\dots, RLWE(g_{d-1} \\boldsymbol{s})  \\right) \n",
    "\\in \\mathcal{R}^{d\\times N}\n",
    "$$\n",
    "\n",
    "Then the inner product between $h(\\boldsymbol{m})$ and $RLWE'( \\boldsymbol{s} )$ will give us RLWE (not RLWE'!!!) encryption of $\\boldsymbol{m\\cdot s}$, $RLWE(\\boldsymbol{m \\cdot s})$.\n",
    "The correctness can be seen as follows:\n",
    "$$\n",
    "\\left<(\\boldsymbol{m}_0, \\dots, \\boldsymbol{m}_{d-1}),  \\left( RLWE(g_0 \\boldsymbol{s}), \\dots, RLWE(g_{d-1} \\boldsymbol{s})  \\right) \\right>\n",
    "= \\sum_{i = 0}^{d-1} (\\boldsymbol{m}_i \\cdot RLWE(g_i \\boldsymbol{s}))\n",
    "= RLWE( \\sum_{i = 0}^{d-1} (\\boldsymbol{m}_i \\cdot g_i \\boldsymbol{s}))\n",
    "= RLWE( \\sum_{i = 0}^{d-1} (\\boldsymbol{m} \\cdot \\boldsymbol{s}))\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2.1. Error analysis (why RLWE'?)\n",
    "\n",
    "We can also get a ciphertext of $RLWE(\\boldsymbol{m}\\boldsymbol{s})$ by multiplying $\\boldsymbol{m}$ to each element  of $RLWE(\\boldsymbol{s})$.\n",
    "In other words, $(\\boldsymbol{m} \\cdot \\boldsymbol{b}, \\boldsymbol{m}\\cdot \\boldsymbol{a})$ is $RLWE(\\boldsymbol{m}\\boldsymbol{s})$, \n",
    "where $RLWE(\\boldsymbol{s}) = (\\boldsymbol{b}, \\boldsymbol{a})$.\n",
    "\n",
    "**Naive multiplication**\n",
    "\n",
    "However, an error $\\boldsymbol{e}$ is contained in $RLWE(\\boldsymbol{s})$, so the decryption $\\boldsymbol{b} + \\boldsymbol{a} \\cdot  \\boldsymbol{s}$ will be given as \n",
    "$$ \n",
    "\\boldsymbol{s} +  \\boldsymbol{e}.\n",
    "$$\n",
    "Thus, the decryption of $RLWE(\\boldsymbol{ms}) = (\\boldsymbol{mb}, \\boldsymbol{ma})$ results in $ \\boldsymbol{ms} +  \\boldsymbol{me}$.\n",
    "\n",
    "**Multiplication using RLWE'**\n",
    "\n",
    "It is okay when $\\boldsymbol{m}$ is small (so it is used to multiply a small constant), but we usually need to to multiply $\\boldsymbol{m}$ uniformly sampled in $\\mathbb{Z}_Q$.\n",
    "In this case, the error variance will be $O(Q^2 \\sigma^2)$, where $\\sigma$ is variance of $\\boldsymbol{e}$, and it overwhelms the message.\n",
    "\n",
    "Instead, if we use the RLWE' product, each ciphertext $RLWE'(g_i \\boldsymbol{s})$ is multiplied by $\\boldsymbol{m}_i$, whose size is smaller than $B$.\n",
    "Assuming they are uniformly distributed, the error variance of $RLWE'(\\boldsymbol{m}_i g_i \\boldsymbol{s})$ should be $B^2/12 \\sigma^2$.\n",
    "Adding $d$ of them, the error variance is  \n",
    "$$\n",
    "dB^2/12 \\sigma^2,\n",
    "$$ \n",
    "where $B = Q^{1/d} \\ll Q$.\n",
    "\n",
    "Naive multiplication is *infeasible* when $\\boldsymbol{m}$ is large, which is exactly the case we want. \n",
    "So, we need RLWE' ciphertext (as key) and multiplication using it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encrypt a key using RLWE' ciphertext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [  1788411,  62139972,  70842809,  ...,   7371080,  14571503,\n",
       "           41590556]],\n",
       "\n",
       "        [[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [ 32409271, 120764302,   5680244,  ...,  24170642,  95132708,\n",
       "           56714077]],\n",
       "\n",
       "        [[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [ 34838124,  76878026,   2307585,  ..., 100510751,  71217482,\n",
       "          110731723]],\n",
       "\n",
       "        [[        0,         0,         0,  ...,         0,         0,\n",
       "                  0],\n",
       "         [ 34404428,  12475759, 118260867,  ..., 126818329,  10023518,\n",
       "          114571333]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it has a dimension of d, 2, N\n",
    "rlwep = torch.zeros(d, 2, N, dtype=torch.int32)\n",
    "\n",
    "# generate the 'a' part\n",
    "rlwep[:, 1, :] = torch.randint(Q, size = (d, N), dtype= torch.int32)\n",
    "\n",
    "rlwep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[       -6,         1,        -9,  ...,        -2,        -3,\n",
       "                  3],\n",
       "         [  1788411,  62139972,  70842809,  ...,   7371080,  14571503,\n",
       "           41590556]],\n",
       "\n",
       "        [[        0,        -2,         3,  ...,        -4,        -1,\n",
       "                 -3],\n",
       "         [ 32409271, 120764302,   5680244,  ...,  24170642,  95132708,\n",
       "           56714077]],\n",
       "\n",
       "        [[       -6,         2,         2,  ...,        -2,         2,\n",
       "                  1],\n",
       "         [ 34838124,  76878026,   2307585,  ..., 100510751,  71217482,\n",
       "          110731723]],\n",
       "\n",
       "        [[       -1,        -6,        -5,  ...,        -4,        -1,\n",
       "                 -2],\n",
       "         [ 34404428,  12475759, 118260867,  ..., 126818329,  10023518,\n",
       "          114571333]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add error on b\n",
    "rlwep[:, 0, :] = torch.round(stddev * torch.randn(size = (d, N)))\n",
    "\n",
    "rlwep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[134217722,         1, 134217719,  ..., 134217726, 134217725,\n",
       "                  3],\n",
       "         [  1788411,  62139972,  70842809,  ...,   7371080,  14571503,\n",
       "           41590556]],\n",
       "\n",
       "        [[        0, 134217726,         3,  ..., 134217724, 134217727,\n",
       "          134217725],\n",
       "         [ 32409271, 120764302,   5680244,  ...,  24170642,  95132708,\n",
       "           56714077]],\n",
       "\n",
       "        [[134217722,         2,         2,  ..., 134217726,         2,\n",
       "                  1],\n",
       "         [ 34838124,  76878026,   2307585,  ..., 100510751,  71217482,\n",
       "          110731723]],\n",
       "\n",
       "        [[134217727, 134217722, 134217723,  ..., 134217724, 134217727,\n",
       "          134217726],\n",
       "         [ 34404428,  12475759, 118260867,  ..., 126818329,  10023518,\n",
       "          114571333]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# following is equal to rlwep %= Q, but a faster version\n",
    "rlwep &= (Q-1)\n",
    "\n",
    "rlwep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do fft for easy a*s\n",
    "rlwepfft = negacyclic_fft(rlwep, N, Q)\n",
    "\n",
    "# now b = -a*s2 + e\n",
    "rlwepfft[:, 0, :] -= rlwepfft[:, 1, :] * s2fft.view(1,N//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 50119422,  47955367,  26405086,  ...,  34553414,   2621741,\n",
       "          119429386],\n",
       "         [  1788410,  62139972,  70842808,  ...,   7371080,  14571503,\n",
       "           41590556]],\n",
       "\n",
       "        [[ 54748284,  51041966, 122316881,  ..., 128565749, 112924448,\n",
       "           93543278],\n",
       "         [ 32409271, 120764301,   5680243,  ...,  24170641,  95132708,\n",
       "           56714076]],\n",
       "\n",
       "        [[ 51752204, 111493915, 130581677,  ...,  94512669,   9606886,\n",
       "           44266644],\n",
       "         [ 34838124,  76878025,   2307585,  ..., 100510751,  71217481,\n",
       "          110731723]],\n",
       "\n",
       "        [[ 65578592,  23817502, 106096809,  ..., 118350180,  19965836,\n",
       "           64858278],\n",
       "         [ 34404428,  12475758, 118260866,  ..., 126818329,  10023518,\n",
       "          114571333]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return back to R_Q\n",
    "rlwepifft = negacyclic_ifft(rlwepfft, N, Q)\n",
    "\n",
    "rlwepifft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      0,       0, 2097152,  ..., 2097152,       0, 2097152],\n",
       "        [      0,       0,   32768,  ...,   32768,       0,   32768],\n",
       "        [      0,       0,     512,  ...,     512,       0,     512],\n",
       "        [      0,       0,       8,  ...,       8,       0,       8]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add decomposition of s1* vec{g}\n",
    "gs1 = gvector * s1\n",
    "\n",
    "gs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlwepifft[:, 0, :] += gs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksk = negacyclic_fft(rlwepifft, N, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksk.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 78261488,  48908637, 104842057,  ..., 124799417,  50596974,\n",
       "         115122275],\n",
       "        [ 29809111,  22452249,  54435983,  ..., 131073647, 100503685,\n",
       "          81545739]], dtype=torch.int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([33554434,        1,       -3, 33554428,       -3,       -1,        3,\n",
      "              -3,       -6,        2], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "mdec = decrypt_from_fft(ctfft, s1fft)\n",
    "print(mdec[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = decompose(ct[1])\n",
    "dctfft = negacyclic_fft(dct, N, Q)\n",
    "dctfft.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 29809111,  22452249,  54435983,  ..., 131073647, 100503685,\n",
      "         81545739], dtype=torch.int32)\n",
      "tensor([ 29809104,  22452248,  54435976,  ..., 131073640, 100503680,\n",
      "         81545736])\n"
     ]
    }
   ],
   "source": [
    "print(ct[1])\n",
    "print(torch.sum(dct*gvector, dim = 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is\n",
    "$$\n",
    "a \\odot RLWE'_{s2}(s1) = RLWE_{s2}(a \\cdot s1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 512]),\n",
       " tensor([[-3.5543e+15-2.1110e+13j, -4.2696e+14+4.5262e+11j,\n",
       "          -7.4475e+13-5.3100e+12j,  ...,\n",
       "          -2.5621e+13-2.7907e+11j, -4.9874e+13-6.9953e+12j,\n",
       "          -1.5260e+14-1.2814e+13j],\n",
       "         [-3.5234e+15-1.0319e+14j, -3.9655e+14-1.3726e+13j,\n",
       "          -9.4416e+13-8.3850e+11j,  ...,\n",
       "          -2.7011e+13+2.3127e+12j, -3.6247e+13-1.1700e+12j,\n",
       "          -1.5074e+14+2.9692e+12j]], dtype=torch.complex128))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodfft = dctfft.view(d, 1, N//2) * ksk\n",
    "prodsumfft = torch.sum(prodfft, dim = 0)\n",
    "\n",
    "prodsumfft.size(), prodsumfft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding $b$ to above, we get\n",
    "$$\n",
    "RLWE_{\\boldsymbol{s2}}(\\boldsymbol{a} \\cdot \\boldsymbol{s1}) + (\\boldsymbol{b}, \\boldsymbol{0}) = RLWE_{\\boldsymbol{s2}}(\\boldsymbol{a} \\cdot \\boldsymbol{s1} + \\boldsymbol{b})\n",
    "= RLWE_{\\boldsymbol{s2}}(\\boldsymbol{m} )\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodsumfft[0] += ctfft[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can decrypt using the switched key $s_2$.\n",
    "\n",
    "Check if the decryption is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:\n",
      " tensor([33554432.,        0.,        0., 33554432.,        0.,        0.,\n",
      "               0.,        0.,        0.,        0.])\n",
      "decrypted:\n",
      " tensor([33841568,   291707,   361954, 33963323,   431422,   478976,   518779,\n",
      "          556394,   623830,   634522], dtype=torch.int32)\n",
      "decrypted (scaled to 1):\n",
      " tensor([1.0086, 0.0087, 0.0108, 1.0122, 0.0129, 0.0143, 0.0155, 0.0166, 0.0186,\n",
      "        0.0189])\n"
     ]
    }
   ],
   "source": [
    "mks = decrypt_from_fft(prodsumfft, s2fft)\n",
    "print(\"m:\\n\",m[:10])\n",
    "print(\"decrypted:\\n\",mks[:10])\n",
    "print(\"decrypted (scaled to 1):\\n\",mks[:10]/(Q//4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
